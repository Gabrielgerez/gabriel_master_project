\makeatletter
\def\input@path{{../}}
\makeatother
\documentclass[../master_thesis.tex]{subfiles}
\begin{document}
\chapter{\ac{MW} Basis}
As stated on the previous chapter, the main goal of computational chemistry is
to approximate systems in order to calculate their energy through the \newline \ac{SE}. %cite please
These systems are completelly described by wave functions \cite{Cohen:1973}.
This means that to approximate a solution to the system is to approximate its
wave function.

In order to construct a solution (wave function) to the \ac{SE} of a given
system one uses sets of orthogonal functions with differing properties. These
sets of functions construct a basis for the space on which the wave functions
are projected into. These sets are thus called basis sets \cite{Cramer:2004}
and they are essential to solving many body systems. In this text we will be
focusing in the \ac{MW} basis from \ac{MRA} methods.

\section{\ac{MRA}}
\subsection{Definition}
Consider that we have a function $\varphi \in L^2(\mathbb{R})$ where its tanslations
and dilations are described as \cite{Schneider:2007}
\begin{equation}
  \varphi^j_k(x) = 2^{\frac{j}{2}}\varphi(2^jx - k),\  j,k \in \mathbb{Z}
\end{equation}.
Where $j$ is the scale of the function and $k$ is the translation of the function
\cite{Sorland}
A space $V_n$ is spanned by translations of $\varphi_{nk}$.This space forms a
hierarchical chain of Linear
subspaces \cite{Beylkin:MRA}:
\begin{equation}
  V_0 \subset V_1 \subset ... \subset V_j \subset ... \subset L^2(\mathbb{R})\label{eq:seqsubspace}
\end{equation}
Where $V_0$ is spanned only by $\varphi_{0,0}(x)=\varphi(x)$ \cite{Sorland}.
The function $\varphi(x)$ satisfies the two-scale difference relations \cite{Beylkin:MRA, Schneider:2007, Sorland}:
\begin{align}
  \begin{split}
    \varphi(x) &= \varphi(2x) + \varphi(2x - 1)\\
    \varphi^j_k(x) &= \varphi^{j+1}_{2k}(2^{j+1}x - 2k) + \varphi^{j+1}_{2k+1}(2^{j+1}x - 2k - 1)
  \end{split}
\end{align}

If relation \ref{eq:seqsubspace} and the following refinement equation holds for $\varphi_{j,k}(x)$
one can call the subspaces $V_n$ or the functions $\varphi_{j,k}(x)$ build a \ac{MRA} of $L_2(\mathbb{R})$.
\begin{equation}
\varphi^j_k(x) = \sum_{k\in\mathbb{Z}} h^{j+1}_k\varphi^{j+1}_k(x)
\end{equation}
Where $h$ is a coefficient characteristic to the transformation between scales.
\subsection{Wavelet \ac{MRA}}
Following from now we will work with the Haar wavelet basis for simplicity \cite{Beylkin:MRA}.
Lets define the Haar function \cite{Schneider:2007} as
\begin{equation}
  \varphi^0_0 = \varphi(x) =
  \begin{cases}
  1 & \text{for} \ x\in [0,1)\\
  0 & \text{elsewhere}
\end{cases}
\end{equation}
Lets now define a second set of subspaces $W_n$. These are the orthogonal complements of $V_n$ \cite{Alpert1993}, also called difference subspaces,
defined as \cite{Beylkin:MRA, Sorland, Alpert1993}.
\begin{equation}
  W_n \oplus V_n = V_{n + 1} \label{eq:diffsubspace}
\end{equation}
The subspaces $W_n$ are then spanned by a set of functions defined by the translations and
dilations of $\psi(x)$:
\begin{equation}
  \psi_k^j(x) = 2^{\frac{j}{2}}\psi(2^jx - k),\  j,k \in \mathbb{Z} \label{eq:haarwavelet}
\end{equation}
Where $\psi(x)$ is called the Haar wavelet \cite{Schneider:2007} and is defined as:
\begin{equation}
  \psi^0_0 = \psi(x) =
  \begin{cases}
  1 & \text{for} \ x\in [0,\frac{1}{2})\\
  -1 & \text{for}\ x\in [\frac{1}{2}, 1)\\
  0 & \text{elsewhere}
\end{cases}
\end{equation}
And $ \varphi$ is related to $\psi$ by the following two-scale difference relation \cite{Beylkin:MRA, Schneider:2007, Sorland}:
\begin{align}
  \begin{split}\label{eq:2scalewavelet}
    \psi(x) &= \varphi(2x) - \varphi(2x - 1)\\
    \psi^j_k(x) &= \psi^{j+1}_{2k}(2^{j+1}x - 2k) + \psi^{j+1}_{2k+1}(2^{j+1}x - 2k - 1)
  \end{split}
\end{align}
The functions $\varphi^j_k$ and $\psi^j_k$ are orthonormal
and dense \cite{Beylkin:MRA, Sorland, SRJensen:2014} in $L^2(\mathbb{R})$.

The Definition on Equation \ref{eq:diffsubspace} can be applied recursivelly in order to
get any space $V_n$ as long as one knows the first subspace $V_0$ and one has a method for constructing the
subspace $W_m$ from $V_0$ and $W_{m-1}$.
\begin{equation}
    V_0 \oplus W_0 \oplus W_1 \oplus ... \oplus W_{n-1}  = V_n \label{eq:recursivespace}
\end{equation}

Projecting a function $f(x)$ unto this basis would be then a weighted linear combination
of the Haar functions, but taking into account the definition on Equation \ref{eq:recursivespace} one arrives
at \cite{Sorland}.
\begin{equation}\label{eq:projectftohaar}
  f(x)\approx \sum^{2^j -1}_k \sum^{N}_j s^j_k\varphi^j_k = s^0_0\varphi^0_0 + \sum^{2^j -1}_k \sum^{N - 1}_jd^j_k\psi^j_k
\end{equation}
where $d$ are the difference coefficients and $s$ are the scaled averages of dyadilic intervals of the function $f(x)$

The scaling coefficients $s^j_k$ are computed by the projection $\braket{\varphi^j_k(x)|f(x)}$.
Likewise the difference coefficients $d^j_k(x)$ are computed by the projection \newline$\braket{\psi^j_k(x)|f(x)}$.
Because of the way the Haar function is defined, we can define of the scaling coefficients as
scaled averages of $f(x)$ at intervals $2^{-j}$ \cite{Sorland, Beylkin:MRA}
\begin{equation}
  s^j_k = \int_{\mathbb{R}}\varphi^j_k(x)f(x)\text{d}x = \int^{2^{-j}(k + 1)}_{2^{-j}k} f(x) \text{d}x\label{eq:scalecoeff1}
\end{equation}
We can then obtain the difference coefficients by using Equations \ref{eq:scalecoeff1}, \ref{eq:haarwavelet} and \ref{eq:2scalewavelet}:
\begin{align}
  \begin{split}\label{eq:diffcoeffint}
    d^{j - 1}_k &= \int_{\mathbb{R}}\psi^{j-1}_k(x)\text{d}x\\
    d^{j - 1}_k &= 2^{\frac{j - 1}{2}}\int_{\mathbb{R}}\psi(2^{j-1}x - k)f(x)\text{d}x\\
    d^{j - 1}_k &= 2^{\frac{j - 1}{2}}\left(\int_{\mathbb{R}}\varphi(2^jx - 2k)f(x)\text{d}x  - \int_{\mathbb{R}}\varphi(2^jx - 2k - 1)f(x)\text{d}x\right)\\
    d^{j - 1}_k &= 2^{\frac{j - 1}{2}}\left( \int^{2^{-j}(2k+1)}_{2^{-j}2k}f(x)\text{d}x - \int^{2^{-j}(2k+2)}_{2^{-j}(2k + 1)}f(x)\text{d}x \right)\\
    d^{j - 1}_k &= \frac{1}{\sqrt{2}}\left(s^{j}_{2k} - s^{j}_{2k+1} \right)
  \end{split}
\end{align}
The scaling coefficients can be obtained in the same manner:
\begin{align}
  \begin{split}\label{eq:scalecoeffint}
    s^{j - 1}_k &= \int_{\mathbb{R}}\varphi^{j-1}_k(x)\text{d}x\\
    s^{j - 1}_k &= 2^{\frac{j - 1}{2}}\int_{\mathbb{R}}\varphi(2^{j-1}x - k)f(x)\text{d}x\\
    s^{j - 1}_k &= 2^{\frac{j - 1}{2}}\left(\int_{\mathbb{R}}\varphi(2^jx - 2k)f(x)\text{d}x  + \int_{\mathbb{R}}\varphi(2^jx - 2k - 1)f(x)\text{d}x\right)\\
    s^{j - 1}_k &= 2^{\frac{j - 1}{2}}\left( \int^{2^{-j}(2k+1)}_{2^{-j}2k}f(x)\text{d}x + \int^{2^{-j}(2k+2)}_{2^{-j}(2k + 1)}f(x)\text{d}x \right)\\
    s^{j - 1}_k &= \frac{1}{\sqrt{2}}\left(s^{j}_{2k} + s^{j}_{2k+1} \right)
  \end{split}
\end{align}

The result of Equations \ref{eq:diffcoeffint} and \ref{eq:scalecoeffint} show us
that we can represent the projection of coefficients unto a coarser scale as an
orthogonal matrix \cite{Sorland, Beylkin:MRA}:
\begin{equation}
  \begin{pmatrix}
    d^{j}_k \\
    s^{j}_k
  \end{pmatrix} =
  \begin{pmatrix}
    \frac{1}{\sqrt{2}} & -\frac{1}{\sqrt{2}} \\
    \frac{1}{\sqrt{2}} & \frac{1}{\sqrt{2}}
  \end{pmatrix}
  \begin{pmatrix}
    s^{j+1}_{2k} \\
    s^{j+1}_{2k+1}
  \end{pmatrix}
\end{equation}
Projecting the coefficients into a more refined scale is just a transpose of the
above matrix:
\begin{equation}
  \begin{pmatrix}
    s^{j+1}_{2k} \\
    s^{j+1}_{2k+1}
  \end{pmatrix} =
  \begin{pmatrix}
    \frac{1}{\sqrt{2}} & \frac{1}{\sqrt{2}} \\
    -\frac{1}{\sqrt{2}} & \frac{1}{\sqrt{2}}
  \end{pmatrix}
  \begin{pmatrix}
    d^{j}_k \\
    s^{j}_k
  \end{pmatrix}
\end{equation}
\subsection{Projecting a gaussian function example}
As an example, lets approximate the function
$f(x) = \frac{10}{\sqrt{\pi}}e^{-100(x - 0.5)^2}$ in $L^2(\mathbb{R})$
with Haar basis up to scale $5$ using \ref{eq:projectftohaar}. Gives us the
following figures.
%put the plots here

\section{\ac{MW} \ac{MRA}}
%weakness of wavelet that might be fixed with multiwavelet
\subsection{Constructing the basis functions in one dimension}
Following the same basics as in the Haar basis from the previous section we can
define a hierarchical set of multiresolution spaces $V_j^l$ where \cite{Frediani:2013}:
\begin{align}
  \begin{split}
    V_j^l \stackrel{\text{def}}{=} \{&f: \text{all polynomials of degree} \leqslant
    l\  \\
    &\text{on}\  (2^{-j}k,2^{-j}(k+1))\ \text{for}\ 0\leqslant k < 2^{n},\\
    &f\  \text{vanishes elsewhere}\}
  \end{split}
\end{align}
and
\begin{equation}
  V_0^l \subset V_1^l \subset ... \subset V^l_j \subset ... \subset L^2(\mathbb{R})
\end{equation}

We again define subspaces $W_j^l$ as the orthogonal complements of $V^l_j$
\cite{Alpert1993} defined as:
\begin{equation}
  V^l_j \oplus W_j^l = V^l_{j+1}
\end{equation}
 with orthogonal basis functions  $h^j_{lk}$ which are translations and dilations of functions $h_l$:
 \begin{equation}
   h^j_{ik}(x) = 2^\frac{j}{2}h_i(2^jx-k), \ i=1, ...,l;\ k \in \mathbb{Z}\label{eq:mwbasisfuncs}
 \end{equation}
 The functions $h_1, ...,h_l$ are piecewise polynomial, orthogonal to lower order polynomials and
 vanish outside $[0,1]$ \cite{Alpert1993}
\begin{align}
  \int_0^1h_i(x)x^m \text{d}x = 0,\ m = 0, 1, ..., l-1
\end{align}
Our aim is to find a set of functions $f_i$ on the interval $[-1,1]$ that can
be used in the construction of $h_1, ...,h_l$ with the following restrictions
\cite{Alpert1993, Beylkin:MRA}:
\begin{enumerate}
  \item functions $f_i$ on the interval $(0,1)$ are polynomials of degree $l-1.$
  \item functions $f_i$ extend to the interval $(-1, 0)$ as even or odd functions
  dependendent to the parity $i + l - 1$.
  \item functions $f_1,...,f_l$ satisfy : $$\int_{-1}^1f_i(x)f_j(x)\text{d}x \equiv \braket{f_j| f_j} = \delta_{ij}, \ i, i = 1, ..., l.$$
  \item functions $f_j$ have vanishing moments, $$\int_{-1}^1f_j(x)x^i\text{d}x = 0, \ i = 0, 1, ..., j+l-2.$$
\end{enumerate}
The functions $f^{(1)}_1, f^{(1)}_2, ..., f^{(1)}_l$ are defined by \cite{Alpert1993}:
\begin{equation}
  f^1_j(x) =
  \begin{cases}
  x^{j-1} & \text{for} \ x\in (0,1)\\
  -x^{j-1} & \text{for}\ x\in (-1, 0)\\
  0 & \text{elsewhere}.
\end{cases}
\end{equation}

The $2l$ functions $1, x,..., x^{l-1} $ and $ f^{(1)}_1, f^{(1)}_2, ..., f^{(1)}_l$ are linearly
independent, thus they span the space of polynomial functions of
degree $< l$ on the intervals $(0, 1)$ and $(-1, 0)$ \cite{Alpert1993, Beylkin:MRA}. We do the
following process to find the functions $f_i$ \cite{Alpert1993}:
\begin{enumerate}
  \item Using the Gram-Schmidt process we orthogonalize $f^{(1)}_j$ with respect to $1, x,..., x^{l-1}$
  giving us the functions $f_j^{(2)}$ for $j = 1, ..., l$.
  \item  We try to find at least one $f^{(2)}_j$
  which is not orthogonal to $x^{l}$ and reorder the functions so that $\braket{f_1^{(2)}| x^{l}} \neq 0$.
  We now need to find an $a_j$ for the equation $f_j^{(3)} = f_j^{(2)}-a_j\cdot f_0^{(2)}$ such that
  $\braket{f_j^{(3)}| x^{l}} = 0\  \text{for}\  l = 2, ..., l$. We repeat this process orthogonalizing
  to $x^{k+1}, ..., x^{2k-2}$, each turn yielding $f_1^{(2)}, f_2^{(3)}, f_3^{(4)}, ..., f_k^{(k+1)}$ such that
  $\braket{f_j^{(j+1)}|x^i} = 0 \ \text{for}\  i\leqslant j+l-2$.
  \item  Lastly we perform the Gram-Schmidt orthogonalization process on
  $f_{l}^{l+1}, \\f_{l-1}^{l}, f_{l-2}^{l-1}, ..., f_{2}^{1}$ in that order to get
  $ f_l, f_{l-1}, ..., f_1$.
\end{enumerate}

We now construct the functions $h_l$ \cite{Alpert1993}:
\begin{equation}
  h_i(x)= \sqrt{2}f_i(2x-1), \ i= 1, ..., l
\end{equation}
which they themselves build the functions in Equation \ref{eq:mwbasisfuncs}
defining a basis for scaling subspace $W_j^l$.

From the definition of these subspaces
we know that we need to define a basis for the subspace $V^l_0$ which is the
orthogonal complement of $W_0^l$ in $V^l_1$ \cite{Alpert1993}. The basis functions
$u_i(x)$ of the subspace $V^l_0$ can be defined using the following two-scale
difference equations \cite{Beylkin1999AdaptiveSO}, which are analogous to the
two-scale difference equations in \ref{eq:2scalewavelet}.
\begin{align}
  h_i(x) &= \sqrt{2}\sum^{l-1}_{j=0}\left(\bar{H}^{(0)}_{ij}h_j(2x) + \bar{H}^{(1)}_{ij}h_j(2x-1)\right), \ i = 0,...,l-1 \\
  u_i(x) &= \sqrt{2}\sum^{l-1}_{j=0}\left(\bar{G}^{(0)}_{ij}h_j(2x) + \bar{G}^{(1)}_{ij}h_j(2x-1)\right), \ i = 0,...,l-1
\end{align}
Where $ \bar{H} \ \text{and}\ \bar{G} $ are quadrature mirror filter matrices \cite{Beylkin1999AdaptiveSO} which have
the following properties:
\begin{align}
  \bar{H}^{(0)}\bar{H}^{(0)T} + \bar{H}^{(1)}\bar{H}^{(1)T} &= \bar{I} \\
  \bar{G}^{(0)}\bar{G}^{(0)T} + \bar{G}^{(1)}\bar{G}^{(1)T} &= \bar{I} \\
  \bar{H}^{(0)}\bar{G}^{(0)T} + \bar{H}^{(1)}\bar{G}^{(1)T} &= \bar{0}
\end{align}
Which can be summarized in the orthogonal block matrix $\bar{U}$ \cite{Beylkin1999AdaptiveSO}
\begin{equation}
  \bar{U} =
  \begin{pmatrix}
    \bar{H}^{(0)} & \bar{H}^{(1)} \\
    \bar{G}^{(0)} & \bar{G}^{(1)}
  \end{pmatrix}
\end{equation}
Which lets us put the two two-scale difference equations in the following way \cite{Sorland}
\begin{equation}
  \begin{pmatrix}
    \vec{h}(x) \\
    \vec{u}(x)
  \end{pmatrix}
  = \sqrt{2}
  \begin{pmatrix}
    \bar{H}^{(0)} & \bar{H}^{(1)} \\
    \bar{G}^{(0)} & \bar{G}^{(1)}
  \end{pmatrix}
  \begin{pmatrix}
    \vec{h}(2x) \\
    \vec{h}(2x-1)
  \end{pmatrix}
\end{equation}
and subsequently
\begin{equation}
  \begin{pmatrix}
    \vec{h}(2x) \\
    \vec{h}(2x-1)
  \end{pmatrix}
  = \frac{1}{\sqrt{2}}
  \begin{pmatrix}
    \bar{H}^{(0)} & \bar{G}^{(0)} \\
    \bar{H}^{(1)} & \bar{G}^{(1)}
  \end{pmatrix}
  \begin{pmatrix}
    \vec{h}(x) \\
    \vec{u}(x)
  \end{pmatrix}
\end{equation}

\subsection{Choices of Scaling functions }
Now that we have stated how to build the scaling and wavelet basis functions
we need to make a choice of functions $f$ to build said basis.
Here we will breifly show two examples of polunomial functions used to create the
basis. These two are the Legendre polynomials and the Lagrange interpolating
polynomials \cite{Beylkin:MRA, Beylkin1999AdaptiveSO}
\paragraph{Legendre basis}
The Legendre scaling function is defined as follows
\begin{align}
  \phi_j(x)
  \begin{cases}
    \sqrt{2j+1} P_j(2x-1), \ x&\in [0,1)\\
    0,\ x&\notin (0, 1)
  \end{cases}
\end{align}
Where $P_j$ are the Legendre polynomials of order $j$ defined in $[-1, 1]$ \cite{Beylkin:MRA}
Following are some examples of the polynomials together with figures of the first few terms
of the functions. These functions have the advantage of being simple to compute,
since each incremental polynomial order only adds a single term to the function.

\paragraph{Lagrange interpolating basis}
  \begin{align}
    \varphi &= \frac{1}{\sqrt{w_i}}l_i(x), \ i = 0, ..., M-1\\
    l_i(x) &= \prod^{M-1}_{k = 0, k\neq i} \frac{x-x_k}{x_i-x_k} \\
    w_i &= \frac{1}{MP^\prime_M(2x_i-1)P_{M-1}(2x_i-1)}
  \end{align}
Where $M$ is the scale of the subspace, the $P$ functions are the Legendre polynomials and
$x_0, ..., x_{M-1}$ are the roots of $P_M(2x-1)$ \cite{Beylkin:MRA}.
These scaling functions have the characteristic of $l_i(x_j)=\delta_{ij}$ simplifying
integrals and thus projections of the basis.
\subsection{Constructing the basis functions in d dimensions}
\section{Operators}
\subsection{\ac{NS} form Representation of Operators}
Lets us define two projection operators $P^k_n \ \text{and}\ Q^k_n $  and their relation as:
\begin{align}
  P^k_n &: \ L^2([0, 1]) \to V^k_n \\
  Q^k_n &:\  L^2([0, 1]) \to W^k_n \\
  Q^k_n &= P^k_{n+1} - P^k_n
\end{align}
%maybe scrap
A function $f$ would then be projected into a scale $n$ by $ f^k_n = P^k_n f $.
Its projection unto a more refined scale would then be $ f_{n+1}^k = f^k_n + df^l_n$
where $df^k_n = Q^k_nf$ \cite{Frediani:2013}.
%maybe scrap
We expand a linear operator $T:\ L^2([0, 1]) \to L^2([0, 1])$ as
\begin{align}
  \begin{split}
    T &= P^k_0TP^k_0 + \sum^\infty_{n=0}\left( P^k_{n+1}TP^k_{n+1} - P^k_nTP^k_n\right)\\
      &=  P^k_0TP^k_0 + \sum^\infty_{n=0}\left(\left(P^k_{n}+Q^k_{n})T(P^k_{n}+Q^k_{n}\right) - P^k_nTP^k_n\right)\\
      &= P^k_0TP^k_0 + \sum^\infty_{n=0}\left(P^k_nTQ^k_n + Q^k_nTP^k_n + Q^k_nTQ^k_n\right)
  \end{split}
\end{align}
We represent the operator $T$ as
\begin{align}
  A^k_n & \stackrel{\text{def}}{=}Q^k_nTQ^k_n: W_n^k \to W_n^k\\
  B^k_n & \stackrel{\text{def}}{=}Q^k_nTP^k_n: V_n^k \to W_n^k\\
  C^k_n & \stackrel{\text{def}}{=}P^k_nTQ^k_n: W_n^k \to V_n^k\\
  T^k_n & \stackrel{\text{def}}{=}P^k_0TP^k_0: V_n^k \to V_n^k
\end{align}
so we can write the \ac{NS} form of the operator $T$ as \cite{Frediani:2013, Beylkin1999AdaptiveSO}
\begin{equation}
  T = T^k_0 + \sum^\infty_{n=0}\left( A^k_n + B^k_n + C^k_n\right)
\end{equation}
We can then apply $T$ on $f$ and get, by using the definitions above, the following
result:
\begin{align}
  \begin{split}
    Tf = g &= \hat{g}^k_0 + \sum^\infty_{n=0}\left(\tilde{g}^k_n + d\tilde{g}^k_n\right)\\
       &= T^k_0f^k_0 +  \sum^\infty_{n=0}\left(\left(A_n^k + C_n^k)df^k_n + B^k_nf^k_n\right)\right)\\
       \hat{g}^k_n &\stackrel{\text{def}}{=} T^k_nf = T^k_nf^k_n\\
       \tilde{g}^k_n &\stackrel{\text{def}}{=} C^k_nf = C^k_nf^k_n\\
       d\tilde{g}^k_n &\stackrel{\text{def}}{=}\left(A^k_n + B^k_n\right)f = A^k_nf^k_n + B^k_nf^k_n
  \end{split}
\end{align}
In practice we truncate this to the fines scale $N+1$ where the following is assumed to be true \cite{Frediani:2013}:
\begin{equation}
  \hat{g}^k_{N+1} \simeq g^k_{N+1} \stackrel{\text{def}}{=} (Tf)^k_{N+1}
\end{equation}

\subsection{Integral operators}

\subsection{Differential operators}

%\section{Software}
\input{acronyms.tex}
\biblio
\end{document}
