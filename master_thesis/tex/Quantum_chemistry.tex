\makeatletter
\def\input@path{{../}}
\makeatother
\documentclass[../master_thesis.tex]{subfiles}
\begin{document}
\chapter{Quantum Chemistry}
\section{\ac{QM}}

\subsection{The Postulates of \ac{QM}}

\ac{QM} are based on a set rules that define operations and states. We will
present these rules as six different postulates of \ac{QM} (sometimes divided
as 5) \cite{Atkins:2011, Cohen:1973}.

\subsubsection{First Postulate}
The first postulate states that everything we can know about a physical system
can be extracted from the wave function $\Psi(x, t)$ of that system
\cite{Atkins:2011}. Additionally at a time $t_0$ the system is defined by
a state vector (or wave function) $\ket{\Psi(t_0)}\in L^2$ that has a defined
finite scalar product as \cite{Cohen:1973}:
\begin{equation}
  \braket{\Psi|\Psi} = \|\ket{\Psi}\|^2 =  \int_{\mathbb{R}^3}\Psi^\star\Psi d\vec{r}
\end{equation}

\subsubsection{Second Postulate}
A generic observable $O$ is represented by the application of a generic operator
$\hat{O}$. Two such observables are the position and momentum of a particle. These are
represented by $\hat{q_i}$ and $\hat{p_i}$ respectively, where
$i = \{x, y, z\}$. These operators fulfill the following commutation relations
\cite{Atkins:2011, Cohen:1973}:
\begin{align}
  \begin{split}
    [q_i, p_j] &= i \hbar \delta_{ij}\\
    [q_i, q_j] &= 0 \\
    [p_i, p_j] &= 0
  \end{split}
\end{align}

The operators that represent observables are hermitian, meaning that
\cite{Cohen:1973}:
\begin{equation}
  \hat{O} = (\hat{O}^{\star})^T = (\hat{O}^T)^{\star} = \hat{O}^{\dagger}
\end{equation}

These operators are linear as well:
\begin{equation}
    \hat{O}(f + g) = \hat{O}f + \hat{O}g\label{eq:oplinearity}
\end{equation}
Where $f$ and $g$ are functions.

\subsubsection{Third Postulate}
Whenmeasuring an observable $O$ on a system $\ket{\Psi}$, The only possible
values of the observable are eigenvalues of the corresponding operator $\hat{O}$
unto the measured system $\Psi$ at its current state $\ket{\Psi_i}$. The \eivals
are solutions to the following equation \cite{Cohen:1973}
\begin{equation}
  \hat{O}\ket{\Psi_i} = o_i \ket{\Psi_i}
\end{equation}
This holds true even if the state measured is not an eigenstate of $\hat{O}$.

We can represent an system statevector $\ket{\Psi}$ that is not an eigenstate
of $\hat{O}$ as a linear combination of eigenstates $\ket{i}$ of the operator
\begin{equation}
  \ket{\Psi} = \sum_i c_i \ket{i}
\end{equation}
where the coefficients $c_i$ are computed as the projection of $\ket{\Psi}$ onto
the eigenstates of the operator.
\begin{equation}\label{eq:projcoeff}
  c_i = \braket{i|\Psi}
\end{equation}
Let us say that we apply the generic operator on one of its eigenstates that
is multiplied with the projection coefficient $c_i$ from Equation \ref{eq:projcoeff}.
This gives us
\begin{equation}
  \hat{O}c_i\ket{i} = c_i\hat{O}\ket{i} = c_i o_i\ket{i} = o_i c_i\ket{i}
\end{equation}
Which tells  us that $c_i\ket{i}$ is also an eigenstate of $\hat{O}$ with the
same \eival as $\ket{i}$. Since $c_i\ket{i}$ is one of the components in the
eigenstate $\ket{\Psi}$ applying the operator on it will always give us exactly
one of its \eivals, with different probabilities  depending on its projection on the set
of eigenstates of the operator \cite{Cohen:1973}. The fourth postulate will give
us the way to calculate this probability.

\subsubsection{Fourth Postulate}
The fourth postulate states the possible probabilities of getting a specific
\eival for a given measurement.
Let $\ket{\Psi_i}$ be an \eifunc of $\hat{O}$ such that:
\begin{equation}
  \hat{O}\ket{\Psi_i} = o_i\ket{i}
\end{equation}
and
\begin{equation}
  \ket{\Psi} = \sum_i c_i \ket{i} \label{eq:lincomb}
\end{equation}
has no degenerate \eival,
The probability of measuring \eival $o_i$ from $\ket{\Psi}$ is given by
\cite{Cohen:1973}:
\begin{align} \label{eq:post4}
  \begin{split}
    \mathscr{P}(o_i) &= \abs{\braket{i|\Psi}}^2\\
                     &= \sum_{j}c_i^\star c_j\braket{i|j}\\
                     &= \sum_{j}c_i^\star c_j\delta_{ij}\\
                     &= \abs{c_i}^2
  \end{split}
\end{align}

Following the equation \ref{eq:post4} the probability of measuring the
\eival $o_i$ from $\ket{\Psi_i}$ is just one. The sum of all the probabilities
for each \eival is:
\begin{equation}
  \sum_i\mathscr{P}(o_i) = \sum_i \abs{c_i}^2 = 1
\end{equation}
Here we have ignored the case for degenerate \eival and continuous spectra of
\eival, where the method is analogous to the one used above. The reader is
invited to look them up themselves in \cite{Cohen:1973, Atkins:2011}.

\subsubsection{Fifth Postulate}
The fifth postulate states that immediately after a measurement where the \eival was $o_i$
the state of the system $\ket{\Psi}$ collapses into a state where the only value one
can measure is $o_i$, that is $ \ket{\Psi_i} $ using the conventions stated in postulate 3 and 4.
This is because before measuring, the probabilities for \textit{any} \eival
is as stated in the fourth postulate. When the value has been measured, though,
the uncertainty does not exists, as the state of the system must be one that gives
exactly that value. The following Equation \ref{eq:post5} represents the postulate.
\begin{equation}\label{eq:post5}
  \ket{\Psi} \stackrel{o_i}{\Rightarrow} \ket{\Psi_i}
\end{equation}

\subsubsection{Sixth Postulate}
The system when undisturbed changes in a deterministic way \cite{Cohen:1973}.
This change is governed by the time dependent \ac{SE} \cite{Cohen:1973, Atkins:2011}:
\begin{equation}\label{eq:tdepSE}
  i\hbar\frac{\partial}{\partial t} \ket{\Psi} = \hat{H}\ket{\Psi}
\end{equation}
Where $\tilde{H}$ is the Hamiltonian operator which has the total energy of the
system as its \eivals.

\subsection{The \ac{SE}}
Lets consider the following \ac{SE} for a particle allowed to move in only one dimension
and where its potential energy varies with position (e.g. the Harmonic oscillator
model \cite{Cohen:1973, Atkins:2014}).
\begin{equation}
  \hat{H}\Psi = \left(-\frac{\hbar^2}{2m}\frac{\partial^2 }{\partial x^2} + \hat{V}(x)\right)\Psi = i\hbar\frac{\partial}{\partial t} \Psi\label{eq:1DSE}
\end{equation}
We can substitute $$\Psi(x, t)=\psi(x)\tau(t)$$ into \ref{eq:1DSE}
by assuming that the wave function can be separated into spatial and time dependent
functions \cite{Atkins:2011}:
\begin{align}
  \begin{split}\label{eq:sepvar1DSE}
    \left(-\frac{\hbar^2}{2m}\frac{\partial^2 }{\partial x^2} + \hat{V}(x)\right)\psi\tau &= i\hbar\frac{\partial}{\partial t} \psi\tau \\
    -\frac{\hbar^2}{2m}\tau\frac{d^2 \psi}{d x^2} + \hat{V}(x)\psi\tau &= i\hbar\psi\frac{d\tau}{d t}\\
    -\frac{\hbar^2}{2m}\frac{1}{\psi}\frac{d^2\psi }{d x^2} + \hat{V}(x) &= i\hbar\frac{1}{\tau}\frac{d\tau}{d t}
  \end{split}
\end{align}
In the last step of the Equation \ref{eq:sepvar1DSE} we divided both sides with $\frac{1}{\tau\psi}$.
This shows us that, since the left-hand side of the equation is only dependent on $x$ and the right-hand
side is only dependent on $t$, no matter how much we change the each of the coordinates, they must always equal to
a constant. This constant will be denoted by $E$ as it is the energy of the system. This gives us the following set of equations \cite{Atkins:2011}:
\begin{subequations}
  \label{eq:sysSE}
  \begin{align}
    -\frac{\hbar^2}{2m}\frac{d^2\psi}{d x^2} + \hat{V}(x)\psi &= E\psi  \label{eq:timeindepWF}\\
    i\hbar\frac{d\tau}{d t} &= E\tau  \label{eq:timedepWF}
  \end{align}
\end{subequations}
Equation \ref{eq:timedepWF} can be solved by observation as \cite{Atkins:2011, Cohen:1973} :
\begin{equation}
  \tau(t) = e^{-iE\frac{t}{\hbar}}
\end{equation}
while the remaining Equation \ref{eq:timeindepWF} can be rewritten as
\begin{equation}
  \hat{H}\psi = E\psi\label{eq:timeindepSE}
\end{equation}
Which is the time-independent \ac{SE} which will be used most on this text.

\section{Two particle system}
A two particle system (such as the \ce{H} or the \ce{He^+} atoms) has a simple
hamiltonian of the form
\begin{equation}
  \hat{H}=\hat{T}_{N}+\hat{T}_{e}+\hat{V}
\end{equation}
where $\hat{T}_N$ and $\hat{T}_e$ are the kinetic energy operators of the nucleus $N$ and
of the electron $e$ and $\hat{V}$ is the Coulomb potential for two particles
\cite{Atkins:2014, Jensen:2017}.
This system has an analytical solution in which one follows the following set
of steps.
\begin{enumerate}
  \item Set a center of mass coordinate system. Since the nucleus is
  $1836.152 673 89$ times more massive than the electron \cite{NIST:2019} we can
  assume that it is the center of mass, therefore we can set it as the center of mass
  and ignore external motion of the atom (we put the kinetic energy of the
  nucleus equal to zero) \cite{Jensen:2017, Atkins:2011}.
  \item Change to spherical coordinates so that the potential operator becomes a
  simple function of the radius.
  \item Separate into radial function $R(r)$ and angular function
  $Y(\theta, \phi)$. The angular function can be separated into two more
  functions $\Theta(\theta)$ and $\Phi(\phi)$.
  \item Solve as three sets of differential equations \cite{Simons:2016}.
\end{enumerate}
Following the steps above, the 2 particle system is analytically solvable.

\section{Many body systems}

For bigger systems, there is no practical way to analytically solve the
\ac{SE} \cite{Jensen:2017}. For one, for each particle, the amount of dimensions that need to be
evaluated increases by three, that is, one can expect the wave function
dimension to increase by a factor of $3N$ for each particle $N$
\cite{Cramer:2004}.

Additionally, the potential energy operator becomes more complicated,as it
would not just have the attractive forces between electron-nucleus,but also the
repulsive forces between all the electrons and between all the nuclei. Both of
these problems add more terms per particle and thus would be impossible to be
solved in a realistic time frame \cite{Jensen:2017}.

\subsection{\ac{BO} approximation}
A many body system consists of $N$ nuclei with mass $m_I$ for each nuclei $I$
and $n$ electrons with mass $m_i$ for each electron $i$. Each nucleus has a
charge $Z_Ie$ and each electron has a charge $-e$, where $Z$ is the atomic
number of the nucleus  and $e$ is the Elementary charge \cite{Atkins:2014}. The $N$ nuclei and $n$
electrons are located in a three dimensional coordinate system where each nucleus $I$ has
coordinates $\vec{R}_I = (x_I, y_I, z_I)$ and each electron has coordinates
$\rvec_i = (x_i, y_i, z_i)$.

We are trying to calculate the total energy and wave functions of the system. For
that we define a time independent \ac{SE} where the wavefunction is dependent on
the coordinates of both the electrons and the nuclei, which we will use a single $\vec{R}$
to the coordinates of all the nuclei and a single $\rvec$ to denote the coordinates
of all the electrons.
\begin{equation}\label{eq:totalheliumSE}
  \hat{H}\Psi(\rvec, \vec{R}) = E \Psi(\rvec, \vec{R})
\end{equation}

Here the Hamiltonian, as with the two particle system, has a potential energy $\hat{V}$ and a
kinetic energy $\hat{T}$ operator. As with the two particle system, we can divide $\hat{T}$ as
a sum of two contributions, an electron contribution $\hat{T}_e$ and a nuclear contribution
$\hat{T}_N$. The only difference is that these contributions are sums over all
the particles  instead of just one each\cite{Cramer:2004}
\begin{align}
  \hat{T}_e &= \sum_i^n \frac{\hbar}{2m_i}\nabla^2_i\\
  \hat{T}_N &= \sum_I^N \frac{\hbar}{2m_I}\nabla^2_I
\end{align}
where $\nabla^2_k$ is the Laplacian operator operating on particle $k$
\begin{equation}
  \nabla^2_k = \left( \ddiff{x_k} + \ddiff{y_k} + \ddiff{z_k} \right)
\end{equation}.

The potential operator, which we define as a coulomb potential, is now much more
complicated. It consists of three contributions: the nucleus-electron attraction
$\hat{V}_{Ne}$, the nucleus-nucleus $\hat{V}_{NN}$ repulsion and the electron-electron
repulsion $\hat{V}_{ee}$ \cite{Cramer:2004}.
\begin{align}
  \hat{V}_{Ne} &= \sum^N_I\sum^n_{i}-\frac{Z_Ie^2}{\abs{\vec{R}_I - \rvec_i}}\\
  \hat{V}_{NN} &= \frac{1}{2}\sum^N_{I \neq J}\frac{Z_IZ_Je^2}{\abs{\vec{R}_I - \vec{R}_J}}\\
  \hat{V}_{ee} &= \frac{1}{2}\sum^n_{i \neq j} \frac{e^2}{\abs{\rvec_i - \rvec_j}}
\end{align}
where $I,\ J$ iterate through the nuclei and $i, \ j$ iterate through the electrons.
We can see now that the
The Hamiltonian is then dependent on the positions of all the electrons and all
the nuclei \cite{Jensen:2017}
\begin{equation}
  \hat{H}(\rvec, \vec{R}) = \hat{T}_e + \hat{T}_N + \hat{V}_{Ne} +\hat{V}_{NN} + \hat{V}_{ee}
\end{equation}
We can see that both repulsions $\hat{V}_{NN}, \hat{V}_{ee}$ have $(N - 1)!$ and $(n - 1)!$ terms
 respectively, while the other terms have much simpler sums {sums over one index in the case of the
kinetic energies and $N\cdot n$ terms in the attraction potential $\hat{V}_Ne$}.

In the Hydrogen atom we could fix the nucleus to the center of mass (static nucleus)
\cite{Jensen:2017}. We can no longer do that in atoms with more than one nuclei, as
the nuclei are moving with respect to each other \cite{Cramer:2004}. Thus we cannot
remove the nuclear kinetic energy term as one can with the Hydrogen atom.

In the \ac{BO}  we assume that since the nuclei of the molecule are more massive
than the electrons (a single proton is $1836.152 673 89$ times more massive
than a proton \cite{NIST:2019}) that the electrons can instantaneously respond to
any change in the configuration of the nuclei \cite{Atkins:2011}. That means that we can solve an
electrical problem for any given nuclear geometry as if the nuclei were static
\cite{Cramer:2004, Jensen:2017, Atkins:2014m}

Following this  assumption we separate the wave function into an electrical
$\Psi_e$ and a nuclear wave function $\Psi_N$
\begin{equation}
  \Psi(\rvec, \vec{R}) = \Psi_N(R)\Psi_e(\rvec; \vec{R})
\end{equation}.
Notice that the nuclear wave function is only dependent on the nuclear coordinates,
while the electrical has both the electron and nuclear coordinates as input. From
our assumption above we say that we solve an electronic \ac{SE} for each geometry
of the molecule, thus the nuclear coordinates  are parametric variables of
the electronic wavefunction (symbolized by the semicolon divider $;$) which remain
constant for each solution of the \ac{SE}.

The electronic \ac{SE} is as follows
\begin{equation}
    \hat{H}_e(\rvec; \vec{R})\Psi_e(\rvec;\vec{R}) = E_e(\vec{R})\Psi_e(\rvec;\vec{R})
\end{equation}
Where the Electronic energy $E_e$ becomes a function of $\vec{R}$ which is solved as
a constant for each nuclear geometry. In the electronic Hamiltonian
\begin{equation}
    \hat{H}_e(\rvec; \vec{R}) = \hat{T}_e + \hat{V}_{Ne} + \hat{V}_{ee} + \hat{V}_{NN}
\end{equation}
we assume that the kinetic energy of the nuclei is zero, but we still need to
compute the nuclear repulsion, but as we are solving for any given geometry we can
safely assume that it is a constant \cite{Cramer:2004}.

Solving the electronic \ac{SE} for all possible nuclear geometries will give us
a \ac{PES} defined by the electronic energy for all the different geometries.
With this we can go on to solve the total \ac{SE} \cite{Jensen:2017}
\begin{equation}
  (T_N + E_e(\vec{R}))\Psi_N(\vec{R}) = E_{tot}\Psi_N(\vec{R})
\end{equation}

The computation of the \ac{PES} can be computationally expensive. Because of this
most practical solutions of the total \ac{SE} are computed through acceleration
methods\cite{Jensen:2017}.


\subsection{Variational Principle}
%need to edit this
Consider a complete set of orthonormal \eifuncs $ \Psi_i$  of the
Hamiltonian $H$. From Equation \ref{eq:lincomb} we build an arbitrary
wave function $\Phi$ with a linear combination of the \eifuncs with
coefficients $c_i$.
\begin{equation}
  \Phi = \sum\limits_ic_i\Psi_i
\end{equation}
We also know from Equation \ref{eq:post4} that the probability of $\Phi$ can
be calculated as shown below;
\begin{equation}
  \braket{\Phi|\Phi} = \sum\limits_i^nc_i^2
\end{equation}
We also know that the wave function $\Phi$ is normalized, so the sum above
should equal to one. Additionally, the expectation value of the Hamiltonian can
be calculated as in Equation \ref{eq:endevaleq} to give us this:
\begin{equation}
  \braket{\Phi|H|\Phi} = \sum\limits_i^nc_i^2E_i\label{eq:genenerg}
\end{equation}
This tells us the the energy of the wave function $\Phi$ can be determined by
knowing the energies $E_i$ of each \eifunc $\psi_i$ and the coefficients
$c_i$ associated with the linear combination that describes $\Phi$
\cite{Cramer:2004}.

We know that for this to be a quantum mechanical system there must be a lowest
energy among all energies $E_i$. We choose to call this lowest energy $E_0$.
Subtracting $E_0$ from Equation \ref{eq:genenerg} to find out the difference
between the calculated energy of the arbitrary wave function $\Phi$ with respect
to the ground state energy gives us:

\begin{equation}
   \sum\limits_i^nc_i^2(E_i - E_0) = \braket{\Phi | H | \Phi} -
   E_0\braket{\Phi | \Phi}
\end{equation}
We know that each term $c_i$ must be greater or equal to zero (non-trivial) and
that the term $(E_i - E_0)$ must be greater or equal to zero as well
\cite{Cramer:2004}, because each individual $E_i$ may add more energy to the
ground state. This leads to the following set of inequalities.

\begin{equation}
  \begin{split} \label{eq:varprin}
    \braket{\Phi | H | \Phi} - E_0\braket{\Phi | \Phi} & \geq 0 \\
    \frac{\braket{\Phi | H | \Phi}}{\braket{\Phi | \Phi}} & \geq E_0
  \end{split}
\end{equation}
We know from Equation \ref{eq:startevaleq} that the inequality in the last term in
\ref{eq:varprin} shows that the energy calculated as an \eival of $\Phi$ is
always greater or equal to zero. This lets us construct our trial wave functions
for the ground state of a system with any basis set. We can assess the quality
of the guess by their associated energies, attempting to reach as low a value
as possible \cite{Cramer:2004}.

\subsection{\ac{SCF}}
%describe building basis functions out of potential wells and potentials out
%basis functions
%have the simplified diagram

\input{acronyms.tex}
\biblio
\end{document}
