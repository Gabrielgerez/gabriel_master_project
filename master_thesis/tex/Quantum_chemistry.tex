\makeatletter
\def\input@path{{../}}
\makeatother
\documentclass[../master_thesis.tex]{subfiles}
\begin{document}
\chapter{Quantum Chemistry}
\section{\ac{QM}}
\subsection{Notation}
When working with qunatum chemistry simplify equations or in order to give a
better intuition on what is possible arithmethically. Therefore it is needed to
clarify what most of the different symbols and representations mean in this
subject. Following are most of the notations used through this paper. Further exceptions to the notation will be
clarified where needed througout the paper.
%order of operations
%commutators
%bra-ket
%orthonormality
%   kronecker delta
Where $\delta_{ij}$ is the Kronecker delta which equals one when $i = j$ and
zero when $ i \neq j$ \cite{ Atkins:2014, Atkins:2011, Cohen:1973, Cramer:2004, Jensen:2017}.
\subsection{The Postulates of \ac{QM}}

\ac{QM} are based on a set rules that define operations and states. We will
present these rules as six different postulates of \ac{QM} (sometimes divided
as 5) \cite{Atkins:2011, Cohen:1973}.

\subsubsection{First Postulate}
The first postulate states that everything we can know about a physical system
can be extracted from the wavefunction $\Psi(x, t)$ of that system
\cite{Atkins:2011}. Additionally at a time $t_0$ the system is defined by
a state vector (or wavefunction) $\ket{\Psi(t_0)}\in L^2$ that has a defined
finite scalar product as \cite{Cohen:1973}:
\begin{equation}
  \braket{\Psi|\Psi} = \|\ket{\Psi}\|^2 =  \int_{R^3}\Psi^\star\Psi d\vec{r}
\end{equation}

\subsubsection{Second Postulate}
An generic observable $O$ is represented by a generic operator $\hat{O}$. Two
such observables are the position and momentum of a particle. These are
represented by $\hat{q_i}$ and $\hat{p_i}$ respectivelly, where
$i = \{x, y, z\}$. These operators fulfill the following commutation relations
\cite{Atkins:2011, Cohen:1973}:
\begin{align}
  \begin{split}
    [q_i, p_j] &= i \hbar \delta_{ij}\\
    [q_i, q_j] &= 0 \\
    [p_i, p_j] &= 0
  \end{split}
\end{align}

The operators that represent observables are hermitian, meaning that
\cite{Cohen:1973}:
\begin{equation}
  \hat{O} = (\hat{O}^{\star})^T = (\hat{O}^T)^{\star} = \hat{O}^{\dagger}
\end{equation}
Which means that they hold the following commutation relation
\cite{Cohen:1973}:
\begin{equation}
  [\hat{O}, \hat{O}^{\dagger}] = 0
\end{equation}
These operators are linear as well:
\begin{equation}
    \hat{O}(f + g) = \hat{O}f + \hat{O}g\label{eq:oplinearity}
\end{equation}
Where $f$ and $g$ are functions.

\subsubsection{Third Postulate}
When applying the generic operator to the state vector, $\hat{O}\ket{\Psi_i}$,
one can only measure of the spectrum of eigenvalues $o_i$ of the operator $\hat{O}$
only one such value. The following equation will hold if $\ket{\Psi_i}$ is an
eigenfunction of $\hat{O}$
\cite{Cohen:1973, Atkins:2014}:
\begin{equation}
  \hat{O}\ket{\Psi_i} = o_i\ket{\Psi_i}\label{eq:startevaleq}
\end{equation}
Where we multiply on the left on both sides of the equation with $\bra{\Psi_i}$
giving us
\begin{equation}
  \bra{\Psi_i}\hat{O}\ket{\Psi_i} = \bra{\Psi_i}o_i\ket{\Psi_i}
\end{equation}
We can take the constant $o_i$ outside the integral, and
use the fact that the wavefunctions are normalized:
\begin{align}
  \begin{split}
    \bra{\Psi_i}\hat{O}\ket{\Psi_i} &= o_i\braket{\Psi_i|\Psi_i}\\
    \bra{\Psi_i}\hat{O}\ket{\Psi_i} &= o_i \label{eq:endevaleq}
  \end{split}
\end{align}
The Equation \ref{eq:startevaleq} is an eigenvalue equation and if the operator is
the Hamiltonian $\hat{H}$ then \ref{eq:startevaleq} becomes the \ac{SE} \cite{Cramer:2004}.

\subsubsection{Fourth Postulate}
The fourth postulate states the possible probabilities of getting a specific
eigen-value for a given measurement.
Let $\ket{\Psi_i}$ be an eigenfunction of $\hat{O}$ such that:
\begin{equation}
  \hat{O}\ket{\Psi_i} = o_i\ket{\Psi_i}
\end{equation}
and
\begin{equation}
  \ket{\Psi} = \sum_i c_i \ket{\Psi_i}
\end{equation}
has no degenerate eigen-values,
The probability of measuring eigen-value $o_i$ from $\ket{\Psi}$ is given by
\cite{Cohen:1973}:
\begin{align} \label{eq:post4}
  \begin{split}
    \mathscr{P}(o_i) &= \abs{\braket{\Psi_i|\Psi}}^2\\
                     &= \sum_{j}c_i^\star c_j\braket{\Psi_i|\Psi_j}\\
                     &= \sum_{j}c_i^\star c_j\delta_{ij}\\
                     &= \abs{c_i}^2
  \end{split}
\end{align}

Following the equation \ref{eq:post4} the probability of measuring the
eigen-value $o_i$ from $\ket{\Psi_i}$ is just one. The sum of all the probabilities
for each eigen-value is:
\begin{equation}
  \sum_i\mathscr{P}(o_i) = \sum_i \abs{c_i}^2 = 1
\end{equation}
Here we have ignored te case for degenerate eigen-values and continuos spctra of
eigen-values, where the method is analogous to the one used above. The reader is
invited to look them up themselves in \cite{Cohen:1973, Atkins:2011}.

\subsubsection{Fifth Postulate}
The fifth postulate states that immediatelly after a measurement where the eigenvalue was $o_i$
the state of the system $\ket{\Psi}$ collapses into a state where the only value one
can measure is $o_i$, that is $ \ket{\Psi_i} $ using the conventions stated in postulate 3 and 4.
This is because before measuring, the probabilities for \textit{any} eigen-value
is as stated in the fourth postulate. When the value has been measured, though,
the uncertainty doesn not exists, as the state of the system must be one that gives
exactly that value. The following Equation \ref{eq:post5} represents the postulate.
\begin{equation}\label{eq:post5}
  \ket{\Psi} \stackrel{o_i}{\Rightarrow} \ket{\Psi_i}
\end{equation}

\subsubsection{Sixth Postulate}
The system when undisturbed changes in a deterministic way \cite{Cohen:1973}.
This change is governed by the time dependent \ac{SE} \cite{Cohen:1973, Atkins:2011}:
\begin{equation}\label{eq:tdepSE}
  i\hbar\frac{\partial}{\partial t} \ket{\Psi} = \tilde{H}\ket{\Psi}
\end{equation}
Where $\tilde{H}$ is the Hamiltonian operator which has the total energy of the
system as its eigen-values.

\subsection{The \ac{SE}}



\section{Two particle system}
\subsection{The Hamiltonian}
Consider a one electron system (such as \ce{H} or \ce{He+}) which contains an
electron and a nucleus, which are described using three dimensional coordinates
$ x, y $ and $ z $. The Hamiltonian contains terms for the kinetic $T$ and
potential energy $V$ contributions of both the nucleus $ N $ and the electron
$ e $. In a one electron system in vaccuum the Hamiltonian would be as follows
\cite{Jensen:2017, Cramer:2004}.
\begin{align}
  \begin{split}
    H   &= T_N + T_e + V \\
    T_N &= -\frac{\hbar^2}{2m_N}\nabla^2_N \\
    T_e &= -\frac{\hbar^2}{2m_e}\nabla^2_e \\
    V   &= -\frac{Z}{||\vec{r}_N - \vec{r}_e||} \label{eq:twopH}
  \end{split}
\end{align}
Where the operator $ \nabla^2$ is the Laplacian computing the second partial
derivative $ \frac{\partial^2}{\partial x^2} + \frac{\partial^2}{\partial y^2} +
\frac{\partial^2}{\partial z^2} $ for the coordinates of the electron $\vec{r}_e$
and the nucleus $\vec{r}_N$, $ m $ is the mass of the electron and the nucleus
depending on the subscript used. The potential is the coulomb interaction
between the electrons, which is calculated by dividing the nuclear charge of the
atom $ Z $ with the distance between the electron and the nucleus
$ ||\vec{r}_N - \vec{r}_e|| $. Note that we will be using Atomic units in all
the equations from here onwards, meaning that, although the equations presented
contain constants such as $\hbar$ in literature such as in \cite{Atkins:2014},
these will be presented with their value in atomic units (which is one for
$\hbar$).

We can see that the kinetic energy operators are separable, as they are only
dependent on their respective particle coordinates. The potential energy
operator, on the other hand, is not separable, as it is dependent in the
coordinates of both the nucleus and the electron.

In order to solve the the \ac{SE} analytically one must first change into a
center of mass coordinate system :
\begin{equation}
  \begin{aligned} \label{eq:cmparam}
    \mathbf{X} &= \frac{m_Nx_N + m_ex_e}{m_N + m_e} ~&&;~ x &&&= x_N - x_e \\
    \mathbf{Y} &= \frac{m_Ny_N + m_ey_e}{m_N + m_e} ~&&;~ y &&&= y_N - y_e \\
    \mathbf{Z} &= \frac{m_Nz_N + m_ez_e}{m_N + m_e} ~&&;~ z &&&= z_N - z_e
  \end{aligned}
\end{equation}
Where the $\mathbf{XYZ}$-coordinates define a system centered in the center of mass,
while the $xyz$-coordinates specify the relative position of the two particles
\cite{Jensen:2017}. Applying this coordinate system to the Hamiltonian in
Equation \ref{eq:twopH} yields:
\begin{equation}
  H = -\frac{1}{2}\nabla^2_{\mathbf{XYZ}} -\frac{1}{2\mu}\nabla^2_{xyz} -
  \frac{Z}{\sqrt{x^2 + y^2 + z^2}}\label{eq:twopHcm}
\end{equation}
Where the first term in Equation \ref{eq:twopHcm} describes the motion of the
whole system with respect to a fixed coordinate system. The second term
describes the relative motion of a pseudo-particle with reduced mass:
\begin{equation}
  \mu = \frac{m_Nm_e}{m_N + m_e} = \frac{m_e}{1 + \frac{m_e}{m_N}}
\end{equation}
Given that the nucleus is more massive than the electron (the nucleus is $1800$
times more massive than the electron in a Hydrogen atom \cite{Jensen:2017})
$\mu$ can be approximated to the mass of the electron $m_e$. This lets us
assume that the nucleus is stationary in relation with the electron.

The third term is the potential energy which still is dependent on the distance
between the two particles. In this center of mass system the distance is just
determined by the $xyz$-coordinates.

The electron's motion occurs at fixed distances from the nucleus and can be
anywhere in a sphere around it. Therefore it is advantageous to use polar
coordinates to solve the \ac{SE}. In this coordinate system $r$ describes the
distance to the center, $\theta$ describing the angle of the particle with
respect to the $z$-axis and $\varphi$ describes the polar angle on the
$xy$-plane. Applying this to the Hamiltonian in Equation \ref{eq:twopHcm} gives
\cite{Atkins:2014}:
\begin{equation}
  \begin{split}\label{eq:SphHcm}
    H_{r\theta\varphi} &= -\frac{1}{2\mu}\nabla^2_{r\theta\varphi}
                          -\frac{Z}{r}\\
    \nabla^2_{r\theta\varphi} &=  \frac{1}{r^2}\frac{\partial}{\partial r}
                                  r^2\frac{\partial}{\partial r}
                                  + \frac{1}{r^2}\Lambda^2 \\
    \Lambda^2 &= \frac{1}{\sin{\theta}}\frac{\partial}{
                 \partial\theta}\sin{\theta}\frac{\partial}{\partial\theta}
                 + \frac{1}{\sin^2{\theta}}\frac{\partial^2}{\partial\varphi^2}
  \end{split}
\end{equation}
The operator $\Lambda^2$ is the Legendrian operator \cite{Atkins:2014}.

\subsection{The Wave Function}
As stated above, the motion of the electron happens around different distances
from the nucleus. This tells us that the wavefunction, as with the Hamiltonian,
is better described with spherical coordinates. As the Potential energy is
dependent only on the radius (distance between particles), we can assume the
wavefunction is separable \cite{Atkins:2014} into two functions, a radial $R(r)$
and an angular $Y(\theta, \varphi)$ wave function.
\begin{equation}
  \Psi(r, \theta, \varphi) = R(r) Y(\theta, \varphi)\label{eq:radangsep}
\end{equation}

The angular wavefunction $Y(\theta, \varphi)$ can be further separated into two
functions $ \Theta(\theta) $ and $\Phi(\varphi)$ \cite{Atkins:2014, Simons:2016},
each dependent on their respective angular variable. $\Phi$ is the Harmonics for a particle in a ring \cite{Atkins:2014}
while $ \Theta $ is represented by the associated Legendre functions.
\begin{equation}
  \begin{split}
    Y(\theta, \varphi) &= \Theta(\theta)\Phi(\varphi)\\
    \Phi(\varphi) &= \\
    \Theta(\theta) &= \\
    P_n^l &=
  \end{split}
\end{equation}

\subsection{The energies}

Applying the hamiltonian in Equation \ref{eq:SphHcm} to the wavefunction in
Equation \ref{eq:radangsep} yields \cite{Atkins:2014}:
\begin{equation}
  \begin{split}
    H_{r\theta\varphi} R(r)Y(\theta, \varphi) &= E R(r)Y(\theta, \varphi)
  \end{split}
\end{equation}
\section{Many body systems}

For bigger systems, there is no practical way to analytically solve the
\ac{SE}. For one, for each particle, the amount of dimensions that need to be
evaluated increases by three, that is, one can expect the wave function
dimension to increase by a factor of $3N$ for each particle $N$
\cite{Cramer:2004}.

Additionally, the potential energy operator becomes more complicated,as it
would not just have the attractive forces between electron-nucleus,but also the
repulsive forces between all the electrons. Both of these problems add more
terms per particle and thus would be impossible to be solved in a realistic
timeframe. %cite
%don't know what to write here

\subsection{Variational Principle}

Consider a complete set of orthonormal eigenfunctions $ \Psi_i$  of the
Hamiltonian $H$. From Equation \ref{eq:lincomb} we build an arbitrary
wave function $\Phi$ with a linear combination of the eigenfunctions with
coefficients $c_i$.
\begin{equation}
  \Phi = \sum\limits_ic_i\Psi_i
\end{equation}
We also know from Equation \ref{eq:arbprob} that the pribability of $\Phi$ can
be calculated as shown below;
\begin{equation}
  \braket{\Phi|\Phi} = \sum\limits_i^nc_i^2
\end{equation}
We also know that the wave function $\Phi$ is normalized, so the sum above
should equal to one. Additionally, the expectation value of the Hamiltonian can
be calculated as in Equation \ref{eq:arbeval} to give us this:
\begin{equation}
  \braket{\Phi|H|\Phi} = \sum\limits_i^nc_i^2E_i\label{eq:genenerg}
\end{equation}
This tells us the the energy of the wave function $\Phi$ can be determined by
knowing the energies $E_i$ of each eigenfunction $\psi_i$ and the coefficients
$c_i$ associated with the linear combination that describes $\Phi$
\cite{Cramer:2004}.

We know that for this to be a quantum mechanical system there must be a lowest
energy among all energies $E_i$. We choose to call this lowest energy $E_0$.
Substracting $E_0$ from Equation \ref{eq:genenerg} to find out the difference
between the calculated energy of the arbitrary wave function $\Phi$ with respect
to the ground state energy gives us:

\begin{equation}
   \sum\limits_i^nc_i^2(E_i - E_0) = \braket{\Phi | H | \Phi} -
   E_0\braket{\Phi | \Phi}
\end{equation}
We know that each term $c_i$ must be greater or equal to zero (non-trivial) and
that the term $(E_i - E_0)$ must be greater or equal to zero as well
\cite{Cramer:2004}, because each individual $E_i$ may add more energy to the
ground state. This leads to the following set of inequalities.

\begin{equation}
  \begin{split} \label{eq:varprin}
    \braket{\Phi | H | \Phi} - E_0\braket{\Phi | \Phi} & \geq 0 \\
    \frac{\braket{\Phi | H | \Phi}}{\braket{\Phi | \Phi}} & \geq E_0
  \end{split}
\end{equation}
We know from Equation \ref{eq:eval} that the inequality in the last term in
\ref{eq:varprin} shows that the energy calculated as an Eigenvalue of $\Phi$ is
always greater or equal to zero. This lets us construct our trial wave functions
for the ground state of a system with any basis set. We can assess the quality
of the guess by their associated energies, attempting to reach as low a value
as possible \cite{Cramer:2004}.

\subsection{\ac{BO} approximation}

The Hamiltonian for many electron systems contains terms for the correlated
motion of the particles \cite{Cramer:2004, Jensen:2017}. This includes the
repulsion and attraction of all the particles to each other. This means that no
particle is moving independently of the other particles. Trying to solve a
\ac{SE} analytically with a Hamiltonian such as this is not possible. In order
to simplify the problem we use the \ac{BO} approximation \cite{Cramer:2004,
Jensen:2017}.

In the \ac{BO} approximation one assumes that the motion of the nucleus is
negligible in comparison to the motion of the electrons \cite{Cramer:2004,
Jensen:2017}. This is because the elecrons are 1800 times less massive than the
protons and electrons and the kinetic energy operator is inverselly
proportional to the mass of the particle. THis way we can imagine the system as
having stationary nucleus and electrons in motion around the nucleus.

By using this assumption we can separate the problem of a \ac{SE} for the whole
system (electron and nuclei) into two separate problems, first solving for the
electron motion, attraction and repulsion energies and second solving for the
kinetic energy of the molecule\cite{Cramer:2004}. By this line of thought one
can write the following set of equations in \ref{eq:BO} based on Equation
\ref{eq:twopH} and the Hamiltonian in \ref{eq:SE} adding the nucleus-nucleus
and electron-electron repulsion potentials, $ V_{NN} $ and $ V_{ee} $
respectivelly.
\begin{equation}
  \begin{split}\label{eq:BO}
    H_{tot}\Psi_{tot}(\vec{R}, \vec{r}) &= E_{tot}\Psi_{tot}(\vec{R},
    \vec{r})\\
    H_{tot} &= H_e + H_N \\
    H_e = T_e + V_{Ne} + V_{ee} ~&;~ H_N = T_N + V_{NN} \\
    \Psi_{tot}(\vec{R}, \vec{r}) &= \Psi_N(\vec{R})\Psi_e(\vec{r}; \vec{R}) \\
    (H_e + V_{NN})\Psi_e(\vec{r}; \vec{R}) &= E_e(\vec{R})\Psi_e(\vec{r};
    \vec{R})\\
    (T_N + E_e(\vec{R}))\Psi_N(\vec{R}) &= E_{tot}\Psi_N(\vec{R})
  \end{split}
\end{equation}

In the equations above, both the total Hamiltonian $H_{tot}$ and total
wave function $\Psi_{tot}$ are divided into electronic and nucleic contributions
($\Psi_e$ and$\Psi_N$ respectivelly). This separation is not complete, as there
still is the nucleus-electron attraction which must be included in the
electronic Hamiltonian $H_e$. Additionally, when solving the electronic problem
we need to take into account the nucleus-nucleus repulsion potential $V_NN$.
For these reasons the electronic wave function $\Psi_e$ is dependent on both the
electron coordinates $\vec{r}$ and nucleus coordinates $\vec{R}$. The
electronic wave function is dependent on the electronic coordinates as
variables, but depends on the nuclei coordinates parametrically
\cite{Jensen:2017}.This means that for each molecule geometry the electronic
problem is solved as if the nucleus was motionless. This leads to the
nucleus-nucleus potential to be a constant for each moelcule geometry.

Solving the electronic problem over different geometries gives rise to a
\ac{PES} on which the molecule exists \cite{Cramer:2004}. This parametric
dependency on the geometry of the molecule means that the electronic energy is
as well dependent on it. This way we can attempt to find a minimum (the method
used for this can vary) for the electronic energy by iterativelly solving the
electronic problem with different geometries. This is important to measure how
good our trial wave function is as according to the variational principle.

Once a minimum has been reached on the \ac{PES} one can go on to solve for the
total energy of the system by doing solving the final equation on \ref{eq:BO}.
This, as according to the variational principle, can also be interated over in
order to minimize the energy.

\subsection{Solving the many body problem}

Now that We have simplified the problem into an electonic \ac{SE} using the
\ac{BO} approximation and we can minimize the energy of a waavfunction built
by any basis set in order to find a good approximation to the ground state
energy using the variational principle. The question that remains is, what does
this function, or basis set look like, and how can we solve the problem with it.
An example of a basis set approach which can be utilized to create a first guess
is the \ac{LCAO} approach.










\input{acronyms.tex}
\biblio
\end{document}
